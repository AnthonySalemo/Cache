{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26651576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "867b1c88",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2507838046.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [1]\u001b[1;36m\u001b[0m\n\u001b[1;33m    self.cache_limit_value = ###\u001b[0m\n\u001b[1;37m                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class ProjectCache:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.cache = {}\n",
    "        self.cache_limit_value = ###\n",
    "        \n",
    "    def __contains__(self, key):\n",
    "        \n",
    "        return key in self.cache\n",
    "    \n",
    "    def current_cache_size(self):\n",
    "        \n",
    "        return len(self.cache)\n",
    "    \n",
    "    def initial_population(self, database):\n",
    "        \n",
    "        #Read from mongoDB database\n",
    "        with open('data.json') as file:\n",
    "            file_data = json.load(file)\n",
    "            \n",
    "        #First look for bottom ten tweets based on number of likes\n",
    "        least_relevant = None\n",
    "        for i in file_data:\n",
    "            if least_relevant is None:\n",
    "                least_relevant = i\n",
    "            \n",
    "            elif i[\"favorite_count\"] < least_relevant[\"favorite_count\"]\n",
    "                least_relevant = i\n",
    "        \n",
    "        add_update(least_relevant[\"id\"], least_relevant) \n",
    "        #This only gets the least relevant. I want to do this 9 more times, then switch to most relevant\n",
    "        \n",
    "        #Then take top n number of tweets, and have some stopping point when an element is not added to the cache\n",
    "        most_relevant = None\n",
    "        for i in file_data:\n",
    "            if most_relevant is None:\n",
    "                most_relevant = i\n",
    "            \n",
    "            elif i[\"favorite_count\"] > most_relevant[\"favorite_count\"]\n",
    "                most_relevant = i\n",
    "        \n",
    "        add_update(most_relevant[\"id\"], most_relevant) \n",
    "        #Now run this part until the cache is identical to the previous iteration.\n",
    "        \n",
    "        #Note that we still use add_update which then uses remove_least_relevant\n",
    "    \n",
    "    def add_update(self, key, value):\n",
    "        \n",
    "        if key not in self.cache and len(self.cache) >= self.cache_limit_value: #if the cache limit is met\n",
    "            self.remove_least_relevant()                                     #then remove least relevant to make room in cache\n",
    "        \n",
    "        self.cache[key] = value                       #this part will fill in all necessary field for the json values\n",
    "        \n",
    "        #Note that if we sort in the add_update section then we just need to remove the \n",
    "        #last element in the remove_least_relevant function\n",
    "        \n",
    "    def remove_least_relevant(self):\n",
    "        \n",
    "        least_relavent = None\n",
    "        for key in self.cache:\n",
    "            if least_relevant is None:\n",
    "                least_relevant = key\n",
    "            \n",
    "            elif self.cache[key][\"favorite_count\"] < self.cache[least_relevant][\"favorite_count\"]:\n",
    "                least_relevant = key\n",
    "                \n",
    "        self.cache.pop(least_relevant)\n",
    "        \n",
    "        \n",
    "        #Write a function that finds the least relavent value's key, then you just have to compare the added/updated key\n",
    "        #With the least relavent\n",
    "    def relevance_factor(self):\n",
    "        \n",
    "        #Should be set up within the database\n",
    "        \n",
    "    def up_to_date(self):\n",
    "        \n",
    "        for key in self.cache:\n",
    "            current_viewed_key = key\n",
    "            if self.cache[key][\"created_at\"] >= (\"7 days\"):\n",
    "                #This part should calculate if it was created over seven days ago, and if so remove from cache\n",
    "                self.pop(current_viewed_key)\n",
    "                \n",
    "        #This up_to_date function will run every 24 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dff8073",
   "metadata": {},
   "source": [
    "Ideas for cache size\n",
    "- If we want to go with memory of cache, we would have to check the size of each of the lowest n elements that is >= the current element being viewed\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
